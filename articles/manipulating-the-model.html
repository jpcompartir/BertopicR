<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="BertopicR">
<title>Manipulating the Model • BertopicR</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Manipulating the Model">
<meta property="og:description" content="BertopicR">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">BertopicR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/modular_approach.html">Interacting with Individual Modules</a>
    <a class="dropdown-item" href="../articles/manipulating-the-model.html">Manipulating the Model</a>
    <a class="dropdown-item" href="../articles/quick_start.html">Topic Modelling without Optimisation</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/jpcompartir/BertopicR" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">



<script src="manipulating-the-model_files/htmlwidgets-1.6.2/htmlwidgets.js"></script><link href="manipulating-the-model_files/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="manipulating-the-model_files/datatables-binding-0.30/datatables.js"></script><link href="manipulating-the-model_files/dt-core-1.13.4/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="manipulating-the-model_files/dt-core-1.13.4/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="manipulating-the-model_files/dt-core-1.13.4/js/jquery.dataTables.min.js"></script><link href="manipulating-the-model_files/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="manipulating-the-model_files/crosstalk-1.2.0/js/crosstalk.min.js"></script><div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Manipulating the Model</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/jpcompartir/BertopicRvignettes/manipulating-the-model.Rmd" class="external-link"><code>vignettes/manipulating-the-model.Rmd</code></a></small>
      <div class="d-none name"><code>manipulating-the-model.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://jpcompartir.github.io/BertopicR/" class="external-link">BertopicR</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org" class="external-link">tidyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="changing-the-model-representation">Changing the Model Representation<a class="anchor" aria-label="anchor" href="#changing-the-model-representation"></a>
</h2>
<pre><code><span><span class="co">#&gt; UMAP(low_memory=False, min_dist=0, n_components=5, n_neighbors=10, random_state=42, verbose=True)</span></span>
<span><span class="co">#&gt; Thu Oct 26 11:30:19 2023 Construct fuzzy simplicial set</span></span>
<span><span class="co">#&gt; Thu Oct 26 11:30:19 2023 Finding Nearest Neighbors</span></span>
<span><span class="co">#&gt; Thu Oct 26 11:30:21 2023 Finished Nearest Neighbor Search</span></span>
<span><span class="co">#&gt; Thu Oct 26 11:30:23 2023 Construct embedding</span></span>
<span><span class="co">#&gt; Thu Oct 26 11:30:24 2023 Finished embedding</span></span></code></pre>
<p>Once you are happy with the topics/clusters that have been formed,
there are a few methods we can use to improve the topic representations
and get a better understanding of what each topic is about.</p>
<p>The representation methods currently available are:</p>
<ol style="list-style-type: decimal">
<li><p><strong>KeyBERT</strong> is a keyword extraction technique that
uses BERT embeddings to represent our topics with appropriate keywords
and phrases.</p></li>
<li><p><strong>MaximalMarginalRelevance</strong> is a concept used to
select the most relevant keywords or phrases while promoting diversity
in keywords. It balances relevance to the topic with distinctiveness
from previously chosen keywords or phrases using a trade-off parameter
called lambda.</p></li>
<li><p><strong>OpenAI</strong> allows us to use their available models
to generate topic summaries. An OpenAI API key is required to access
their api and models (to set this you should use
Sys.setenv(“OPENAI_API_KEY” = “sk-”)).</p></li>
<li><p><strong>HuggingFace</strong> allows us to use their available
models to generate topic summaries. Unlike with OpenAI, you will not
need an API key and this is completely free. However, the models are not
as sophisticated as some of OpenAI’s.</p></li>
</ol>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">representation_keybert</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_representation_keybert.html">bt_representation_keybert</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                                    documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                                    document_embeddings <span class="op">=</span> <span class="va">embeddings</span>,</span>
<span>                                                    embedding_model <span class="op">=</span> <span class="va">embedder</span>,</span>
<span>                                                    top_n_words <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                                                    nr_repr_docs <span class="op">=</span> <span class="fl">50</span>,</span>
<span>                                                    nr_samples <span class="op">=</span> <span class="fl">500</span>,</span>
<span>                                                    nr_candidate_words <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="va">representation_mmr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_representation_mmr.html">bt_representation_mmr</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                            embedding_model <span class="op">=</span> <span class="va">embedder</span>,</span>
<span>                                            diversity <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">representation_openai</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_representation_openai.html">bt_representation_openai</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                                  documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                                  openai_model <span class="op">=</span> <span class="st">"gpt-3.5-turbo"</span>,</span>
<span>                                                  nr_repr_docs <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                                                  chat <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                                                  api_key <span class="op">=</span> <span class="st">"sk-"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">representation_hf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_representation_hf.html">bt_representation_hf</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                          documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                          task <span class="op">=</span> <span class="st">"text2text-generation"</span>,</span>
<span>                                          hf_model <span class="op">=</span> <span class="st">"google/flan-t5-base"</span>,</span>
<span>                                          default_prompt <span class="op">=</span> <span class="st">"keywords"</span><span class="op">)</span></span></code></pre></div>
<p>Now that we have trialled a few representation methods, we can look
at how they compare to default representations and we should be able to
get a good idea of what each topic is about. You will notice that the
gpt-3.5 model gives the most coherent topic representation and it would
be easy to just take that as gospel and chose a topic title based on
that. It is important to remember, like with the other representation
methods, only the number you input for nr_repr_docs in
bt_representation_openai has been sent to the model and for a large
topic, these documents may not represent the topic as a whole.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">topic_representations</span> <span class="op">&lt;-</span> <span class="va">topic_model</span><span class="op">$</span><span class="fu">get_topic_info</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>keybert <span class="op">=</span> <span class="va">representation_keybert</span>,</span>
<span>         mmr <span class="op">=</span> <span class="va">representation_mmr</span>,</span>
<span>         <span class="co"># openai = representation_openai,</span></span>
<span>         flanT5 <span class="op">=</span> <span class="va">representation_hf</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Representative_Docs</span><span class="op">)</span></span>
<span></span>
<span><span class="va">topic_representations</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Topic</span>, <span class="op">-</span><span class="va">Count</span>, <span class="op">-</span><span class="va">Name</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>keybert <span class="op">=</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_replace.html" class="external-link">str_replace_all</a></span><span class="op">(</span><span class="va">keybert</span>, <span class="st">"_"</span>,<span class="st">", "</span><span class="op">)</span>,</span>
<span>         mmr <span class="op">=</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_replace.html" class="external-link">str_replace_all</a></span><span class="op">(</span><span class="va">mmr</span>, <span class="st">"_"</span>,<span class="st">", "</span><span class="op">)</span>,</span>
<span>         Representation <span class="op">=</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_replace.html" class="external-link">str_replace_all</a></span><span class="op">(</span><span class="va">Representation</span>, <span class="st">"_"</span>,<span class="st">", "</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">DT</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/DT/man/datatable.html" class="external-link">datatable</a></span><span class="op">(</span>options <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>scrollX <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: There was 1 warning in `mutate()`.</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> In argument: `Representation = stringr::str_replace_all(Representation, "_",</span></span>
<span><span class="co">#&gt;   ", ")`.</span></span>
<span><span class="co">#&gt; Caused by warning in `stri_replace_all_regex()`:</span></span>
<span><span class="co">#&gt; <span style="color: #BBBB00;">!</span> argument is not an atomic vector; coercing</span></span></code></pre></div>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-032942187589e245e2d4" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-032942187589e245e2d4">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66"],["c(\"boy\", \"hole\", \"time\", \"broke\", \"write\", \"paper\", \"large\", \"dark\", \"dust\", \"fast\")","c(\"barn\", \"dirt\", \"watch\", \"size\", \"quick\", \"note\", \"blow\", \"clear\", \"tell\", \"spring\")","c(\"needs\", \"just\", \"strong\", \"cause\", \"crack\", \"tried\", \"watch\", \"stop\", \"office\", \"need\")","c(\"smell\", \"cloth\", \"clean\", \"dirt\", \"times\", \"tender\", \"neat\", \"burned\", \"bring\", \"dust\")","c(\"mark\", \"low\", \"beat\", \"struck\", \"base\", \"lead\", \"jump\", \"clock\", \"quite\", \"sat\")","c(\"taste\", \"tree\", \"served\", \"sent\", \"cut\", \"fine\", \"salt\", \"ice\", \"lack\", \"air\")","c(\"cold\", \"let\", \"start\", \"lay\", \"ice\", \"smell\", \"deep\", \"hot\", \"work\", \"air\")","c(\"friends\", \"note\", \"leave\", \"girl\", \"new\", \"serve\", \"words\", \"took\", \"set\", \"write\")","c(\"box\", \"square\", \"seen\", \"wooden\", \"poor\", \"neat\", \"paper\", \"slide\", \"salt\", \"bright\")","c(\"need\", \"food\", \"spring\", \"needed\", \"came\", \"horse\", \"road\", \"man\", \"best\", \"way\")","c(\"cover\", \"steady\", \"went\", \"shone\", \"dark\", \"edge\", \"red\", \"hole\", \"mark\", \"green\")","c(\"screen\", \"went\", \"let\", \"gives\", \"burned\", \"lack\", \"house\", \"set\", \"leaves\", \"brown\")","c(\"slide\", \"tight\", \"cord\", \"wooden\", \"glass\", \"open\", \"crack\", \"cover\", \"needed\", \"paint\")","c(\"drifts\", \"seen\", \"pink\", \"stood\", \"salt\", \"low\", \"fun\", \"edge\", \"came\", \"rose\")","c(\"went\", \"size\", \"jump\", \"start\", \"spring\", \"home\", \"fast\", \"straight\", \"rose\", \"ran\")","c(\"big\", \"torn\", \"stop\", \"port\", \"brought\", \"blow\", \"sharp\", \"lost\", \"cut\", \"clear\")","c(\"tired\", \"port\", \"drink\", \"taste\", \"serve\", \"hold\", \"smell\", \"strong\", \"water\", \"makes\")","c(\"quick\", \"gave\", \"failed\", \"street\", \"saw\", \"house\", \"dog\", \"black\", \"white\", \"light\")","c(\"sun\", \"bowl\", \"shone\", \"pink\", \"soft\", \"blue\", \"rose\", \"came\", \"light\", \"hung\")","c(\"office\", \"needed\", \"bank\", \"ran\", \"boy\", \"wall\", \"\", \"\", \"\", \"\")","c(\"tree\", \"room\", \"gives\", \"dark\", \"green\", \"white\", \"light\", \"leaves\", \"large\", \"makes\")","c(\"tree\", \"near\", \"fall\", \"drifts\", \"brought\", \"edge\", \"air\", \"round\", \"way\", \"high\")","c(\"desk\", \"chair\", \"sat\", \"cover\", \"corner\", \"blue\", \"light\", \"floor\", \"man\", \"strong\")","c(\"barn\", \"fall\", \"china\", \"bank\", \"soft\", \"street\", \"chair\", \"lost\", \"broke\", \"black\")","c(\"bank\", \"poor\", \"jump\", \"free\", \"great\", \"add\", \"fence\", \"store\", \"good\", \"\")","c(\"black\", \"stain\", \"pencil\", \"lead\", \"heavy\", \"dried\", \"covered\", \"paint\", \"coat\", \"blue\")","c(\"right\", \"dog\", \"day\", \"came\", \"small\", \"grass\", \"young\", \"\", \"\", \"\")","c(\"left\", \"cord\", \"cloth\", \"gold\", \"day\", \"like\", \"fine\", \"\", \"\", \"\")","c(\"road\", \"dirt\", \"wide\", \"street\", \"low\", \"lay\", \"deep\", \"sun\", \"men\", \"sharp\")","c(\"fence\", \"corner\", \"long\", \"square\", \"slide\", \"leaves\", \"grass\", \"high\", \"\", \"\")","c(\"add\", \"drop\", \"comes\", \"great\", \"fast\", \"set\", \"\", \"\", \"\", \"\")","c(\"store\", \"start\", \"serve\", \"friends\", \"corner\", \"girl\", \"night\", \"left\", \"\", \"\")","c(\"short\", \"room\", \"write\", \"tell\", \"struck\", \"little\", \"fun\", \"rare\", \"make\", \"dull\")","c(\"words\", \"times\", \"leave\", \"right\", \"lost\", \"don\", \"strong\", \"\", \"\", \"\")","c(\"tried\", \"drop\", \"cause\", \"bad\", \"right\", \"lost\", \"just\", \"hard\", \"new\", \"old\")","c(\"sent\", \"rings\", \"hold\", \"gold\", \"worn\", \"girl\", \"kept\", \"used\", \"\", \"\")","c(\"quick\", \"pencil\", \"carved\", \"hung\", \"cut\", \"wide\", \"brown\", \"sharp\", \"bright\", \"fine\")","c(\"horse\", \"tall\", \"day\", \"night\", \"brown\", \"way\", \"\", \"\", \"\", \"\")","c(\"saw\", \"hole\", \"dog\", \"takes\", \"makes\", \"good\", \"small\", \"\", \"\", \"\")","c(\"pink\", \"blue\", \"used\", \"tall\", \"small\", \"\", \"\", \"\", \"\", \"\")","c(\"food\", \"drink\", \"cup\", \"salt\", \"sweet\", \"add\", \"hot\", \"makes\", \"fine\", \"\")","c(\"torn\", \"heavy\", \"dried\", \"stood\", \"house\", \"floor\", \"wall\", \"red\", \"\", \"\")","c(\"rings\", \"clean\", \"bright\", \"make\", \"used\", \"wall\", \"high\", \"\", \"\", \"\")","c(\"long\", \"carved\", \"base\", \"read\", \"form\", \"large\", \"\", \"\", \"\", \"\")","c(\"pot\", \"tired\", \"served\", \"china\", \"taste\", \"sweet\", \"cold\", \"worn\", \"brown\", \"\")","c(\"open\", \"cloth\", \"make\", \"good\", \"\", \"\", \"\", \"\", \"\", \"\")","c(\"tight\", \"open\", \"watch\", \"glass\", \"covered\", \"barn\", \"door\", \"don\", \"kept\", \"\")","c(\"pot\", \"failed\", \"covered\", \"contents\", \"hard\", \"good\", \"old\", \"\", \"\", \"\")","c(\"saw\", \"hold\", \"dry\", \"kept\", \"best\", \"hard\", \"used\", \"\", \"\", \"\")","c(\"tried\", \"shone\", \"quite\", \"failed\", \"worn\", \"like\", \"man\", \"dull\", \"new\", \"old\")","c(\"served\", \"free\", \"far\", \"comes\", \"bowl\", \"rare\", \"round\", \"\", \"\", \"\")","c(\"men\", \"stop\", \"steady\", \"work\", \"act\", \"man\", \"hard\", \"\", \"\", \"\")","c(\"clock\", \"little\", \"rare\", \"needs\", \"work\", \"box\", \"gold\", \"good\", \"\", \"\")","c(\"door\", \"needed\", \"bad\", \"old\", \"\", \"\", \"\", \"\", \"\", \"\")","c(\"neat\", \"time\", \"right\", \"needs\", \"\", \"\", \"\", \"\", \"\", \"\")","c(\"bring\", \"long\", \"home\", \"took\", \"road\", \"best\", \"\", \"\", \"\", \"\")","c(\"note\", \"lead\", \"cause\", \"bad\", \"small\", \"like\", \"don\", \"\", \"\", \"\")","c(\"near\", \"screen\", \"green\", \"\", \"\", \"\", \"\", \"\", \"\", \"\")","c(\"short\", \"gave\", \"far\", \"sweet\", \"street\", \"white\", \"tall\", \"like\", \"girl\", \"\")","c(\"port\", \"glass\", \"food\", \"cup\", \"contents\", \"struck\", \"broke\", \"tall\", \"red\", \"\")","c(\"worn\", \"stain\", \"drop\", \"dust\", \"beat\", \"right\", \"big\", \"floor\", \"round\", \"old\")","c(\"great\", \"lack\", \"young\", \"makes\", \"old\", \"\", \"\", \"\", \"\", \"\")","c(\"coat\", \"torn\", \"quite\", \"tall\", \"white\", \"gold\", \"\", \"\", \"\", \"\")","c(\"room\", \"form\", \"night\", \"dull\", \"\", \"\", \"\", \"\", \"\", \"\")","c(\"dog\", \"tender\", \"drink\", \"grass\", \"spring\", \"lay\", \"home\", \"young\", \"\", \"\")","c(\"free\", \"men\", \"lack\", \"new\", \"don\", \"night\", \"way\", \"\", \"\", \"\")"],["outliers","dirt, cut, ran, barn, blow, spring, wide, clear, sharp, mark","crack, heavy, time, strong, takes, set, need, office, tried, needs","burned, sharp, dirt, cloth, dust, floor, tender, water, makes, deep","dull, struck, took, straight, lead, jump, low, kept, clock, tired","cut, salt, tree, ice, taste, kept, air, hard, served, large","grass, wall, work, air, ice, smell, deep, green, cold, hot","clear, note, words, serve, took, leave, make, write, wide, friends","bright, wooden, poor, paper, seen, salt, red, high, neat, square","food, came, man, spring, best, road, way, need, horse, used","paper, light, cover, dull, round, dark, set, hole, box, mark","leaves, burned, house, lack, went, brown, kept, screen, man, gives","paint, cord, crack, wooden, wall, glass, cut, cover, dull, best","stood, drifts, dry, salt, came, seen, water, edge, took, rose","fast, ran, went, jump, straight, home, makes, rose, spring, like","cut, water, sharp, clear, small, hard, blow, torn, brought, lost","serve, water, drink, smell, taste, strong, hot, tired, makes, old","light, saw, quick, house, failed, dog, black, white, street, gave","air, hung, soft, light, sun, bright, shone, came, clear, rose","ran, wall, bank, boy, needed, office","room, light, tree, leaves, large, dark, gives, green, strong, makes","round, tree, fall, drifts, air, high, near, brought, edge, way","floor, cover, chair, wall, red, light, desk, strong, high, blue","broke, red, black, floor, china, street, barn, set, fall, big","jump, fence, great, good, store, poor, bank, free, add","pencil, paint, covered, dried, heavy, lead, hard, stain, black, blue","grass, came, day, small, young, dog, right","cloth, day, gold, like, cord, fine, left","lay, men, sun, dirt, sharp, high, hot, low, wide, road","grass, fence, leaves, corner, long, high, square, slide","drop, fast, comes, set, great, add","serve, night, start, left, store, corner, friends, girl","dull, write, tell, make, room, good, makes, little, struck, fun","don, leave, lost, times, right, words, strong","drop, tried, just, right, hard, new, bad, cause, old, lost","rings, gold, worn, hold, kept, girl, used, sent","pencil, hung, bright, carved, sharp, wide, brown, cut, fine, quick","night, day, brown, way, tall, horse","makes, small, good, hole, takes, saw, dog","small, tall, blue, pink, used","salt, food, drink, cup, sweet, hot, fine, makes, add","dried, stood, torn, heavy, floor, house, red, wall","bright, wall, clean, make, rings, high, used","base, long, read, carved, form, large","cold, worn, served, tired, sweet, taste, brown, china, pot","cloth, good, make, open","don, watch, barn, glass, door, covered, tight, kept, open","old, hard, covered, good, failed, pot, contents","hard, hold, saw, dry, best, kept, used","dull, like, worn, tried, new, shone, failed, old, man, quite","served, bowl, round, rare, far, comes, free","hard, work, act, stop, men, man, steady","needs, good, work, box, rare, gold, little, clock","door, old, bad, needed","needs, neat, time, right","best, took, road, home, long, bring","like, note, bad, lead, cause, don, small","green, screen, near","white, tall, short, like, sweet, girl, far, street, gave","glass, red, broke, port, cup, struck, food, tall, contents","round, beat, big, stain, floor, old, right, dust, worn, drop","old, lack, young, great, makes","gold, coat, white, torn, quite, tall","dull, night, room, form","grass, tender, dog, lay, drink, home, young, spring","men, don, way, night, new, lack, free"],["outliers","barn, watch, size, note, clear, spring, quick, blow, tell, dirt","crack, office, strong, watch, stop, cause, just, tried, need, needs","dirt, cloth, dust, clean, tender, burned, neat, bring, times, smell","clock, jump, low, sat, lead, base, quite, beat, struck, mark","ice, tree, air, salt, sent, served, cut, lack, fine, taste","cold, start, let, work, smell, lay, air, deep, ice, hot","write, serve, note, leave, words, set, took, new, girl, friends","salt, bright, slide, poor, square, seen, paper, neat, wooden, box","food, spring, horse, road, man, best, way, came, needed, need","cover, steady, mark, green, red, shone, dark, hole, went, edge","burned, brown, leaves, set, house, let, lack, went, gives, screen","paint, crack, cord, cover, glass, wooden, tight, open, needed, slide","rose, pink, edge, salt, stood, seen, low, came, fun, drifts","jump, rose, spring, size, straight, fast, start, ran, home, went","sharp, cut, port, torn, clear, blow, lost, stop, brought, big","smell, port, serve, water, taste, drink, hold, makes, strong, tired","light, street, saw, dog, house, failed, white, black, gave, quick","sun, bowl, hung, pink, rose, shone, came, blue, light, soft","bank, wall, ran, boy, needed, , , , , office","leaves, light, green, room, white, dark, makes, gives, large, tree","fall, drifts, air, round, high, edge, way, brought, near, tree","chair, blue, man, strong, cover, light, sat, floor, corner, desk","chair, broke, black, soft, china, fall, bank, lost, street, barn","fence, jump, poor, add, free, great, store, good, , bank","pencil, paint, stain, lead, dried, coat, covered, blue, heavy, black","grass, dog, day, small, young, came, , , , right","cloth, cord, gold, day, like, fine, , , , left","sharp, sun, men, low, lay, wide, deep, dirt, street, road","fence, slide, grass, square, corner, high, leaves, long, , ","drop, fast, set, great, comes, , , , , add","store, serve, corner, night, start, girl, friends, left, , ","dull, write, room, make, rare, tell, fun, struck, little, short","lost, leave, strong, times, don, right, , , , words","drop, lost, bad, right, cause, old, new, just, hard, tried","rings, gold, girl, worn, hold, kept, , , used, sent","pencil, sharp, carved, hung, cut, brown, bright, wide, fine, quick","horse, night, brown, tall, day, way, , , , ","small, dog, hole, takes, good, makes, , , , saw","pink, tall, small, used, blue, , , , , ","salt, sweet, add, hot, fine, cup, makes, drink, , food","red, dried, floor, wall, stood, house, heavy, , , torn","rings, bright, high, clean, wall, make, , , , used","base, carved, form, read, large, , , , , long","pot, china, cold, tired, brown, worn, sweet, served, taste, ","cloth, make, good, , , , , , , open","door, barn, glass, watch, don, open, kept, covered, , tight","pot, failed, covered, contents, hard, good, old, , , ","saw, dry, hold, hard, best, kept, used, , , ","shone, dull, worn, old, quite, man, new, like, failed, tried","bowl, rare, round, far, free, comes, , , , served","men, steady, stop, act, work, hard, man, , , ","clock, rare, gold, needs, box, little, work, good, , ","door, old, bad, needed, , , , , , ","time, needs, right, , , , , , , neat","road, home, long, best, took, , , , , bring","lead, small, cause, like, bad, don, , , , note","screen, green, , , , , , , , near","short, street, white, girl, tall, gave, sweet, far, like, ","glass, broke, cup, red, tall, food, struck, contents, , port","stain, floor, dust, drop, right, beat, old, round, big, worn","young, lack, old, makes, , , , , , great","coat, gold, torn, tall, quite, white, , , , ","dull, night, form, , , , , , , room","tender, spring, grass, drink, lay, home, young, , , dog","night, men, lack, don, way, new, , , , free"],[["outliers"],["a quick note to tell a horse that it is a little too big for its"],["i need to stop cracking my office"],["bringing a smoky smell to a room"],["sat at the base of the tee against the clock"],["iceberg"],["laying ice in the air"],["a note taken from a girl who took a new set of words from her friends"],["a box of salt and a square of paper"],["horse came to man for food in spring"],["green and red striped cover with a dark red edge"],["burnt screen in a house"],["a wooden cover for a crack in the glass"],["pink roses dangling from the edge of a cliff"],["a girl ran into a home and ran straight into the roses in spring"],["a splinter cut to the port"],["port a drink"],["a dog gave a quick, black, white, and black light to a house"],["pink roses hung in a bowl"],["a boy ran through the wall of a bank"],["a large tree gives a dark, green, white, and green light to a"],["drifting tree near the edge of a cliff in the air"],["a strong man sat on a desk covered in blue light on the floor"],["broken chair in a barn"],["a giraffe jumps free from a fence in a store"],["a black and blue painting"],["small dog came out of the grass on a sunny day"],["gold cords"],["a man lay on the road with a sharp blade in the sun"],["a fence that slides down a long square of grass"],["add some speed to your set with this awesome drop"],["a girl serving a girl in a corner at a store"],["a little bit of fun"],["i lost my right to leave my home"],["i lost my job"],["girl in gold ring kept in a ring"],["pencil sharpener"],["horse in the dark with a brown coat and brown eyes"],["small dog taking a saw"],["small pink and blue striped dress"],["add salt to a cup of hot food"],["red walls and floors of a house"],["ring made of glass high in the wall"],["carved base of a large carved wooden statue"],["china served cold with brown chinese food"],["make good cloth"],["a barn with a locked door and a locked window"],["old pot"],["a saw"],["old man"],["free round of squid in a bowl"],["man stops to work hard"],["clock needs gold"],["old door needed"],["need neatness"],["bringing home the best home"],["don't like lead"],["green screen near the tv"],["i like the short white girl who gave me a sweet street hug"],["broken glass in a port"],["old floor with big stains"],["a young man who lacks a sense of humor"],["a tan coat with gold ruffles"],["dark room with dark form"],["a dog laying in the grass"],["free men don't need to be free at night"]]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Representation<\/th>\n      <th>keybert<\/th>\n      <th>mmr<\/th>\n      <th>flanT5<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"scrollX":true,"columnDefs":[{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div class="section level2">
<h2 id="modifying-topics">Modifying Topics<a class="anchor" aria-label="anchor" href="#modifying-topics"></a>
</h2>
<p>Two of the biggest inconveniences that using hdbscan clustering
introduces is the generation of large numbers of clusters (topics) and
the presence of what can be huge numbers of outliers. In order for our
topic analysis to be practical and digestible, we will likely want to
reduce the number of topics and, depending on our use case, we may want
to reduce the number of outliers.</p>
<div class="section level3">
<h3 id="merging-topics">Merging Topics<a class="anchor" aria-label="anchor" href="#merging-topics"></a>
</h3>
<p>Particularly when using hdbscan we can end up with a large number of
topics and it can be useful to merge some of these topics which we think
are suitably similar. We can get a certain idea about this from the
topic descriptions that we have already generated, but it can also be
useful to look at the data more closely before merging.</p>
<div class="section level4">
<h4 id="hierarchical-clustering">Hierarchical Clustering<a class="anchor" aria-label="anchor" href="#hierarchical-clustering"></a>
</h4>
<p>Hdbscan clustering forms clusters through a hierarchical processes
which you can visualise with a dendrogram. This can be useful when
merging topics as you can see how clusters split to become the topics
that emerged from our topic modelling process. The x-axis here is a
measure of the distance between topic embeddings, so when clusters split
at a higher x-value there is a larger distance between their embeddings.
We can see that for this particular dataset, the clusters split into
their final topics quite early on in the hierarchy and so it might not
be appropriate to merge topics based on how they have emerged in the
hierarchy.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hierarchical_topics</span> <span class="op">&lt;-</span> <span class="va">topic_model</span><span class="op">$</span><span class="fu">hierarchical_topics</span><span class="op">(</span><span class="va">sentences</span><span class="op">)</span></span>
<span><span class="va">topic_model</span><span class="op">$</span><span class="fu">visualize_hierarchy</span><span class="op">(</span>hierarchical_topics <span class="op">=</span> <span class="va">hierarchical_topics</span><span class="op">)</span><span class="op">$</span><span class="fu">show</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code>#&gt; 
  0%|          | 0/64 [00:00&lt;?, ?it/s]
 20%|##        | 13/64 [00:00&lt;00:00, 127.96it/s]
 48%|####8     | 31/64 [00:00&lt;00:00, 158.37it/s]
 81%|########1 | 52/64 [00:00&lt;00:00, 178.80it/s]
100%|##########| 64/64 [00:00&lt;00:00, 179.37it/s]</code></pre>
<div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script charset="utf-8" src="https://cdn.plot.ly/plotly-2.24.1.min.js"></script><div id="6b58c264-859d-4a8d-803f-ad6df1035b83" class="plotly-graph-div" style="height:1175px; width:1000px;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("6b58c264-859d-4a8d-803f-ad6df1035b83")) {                    Plotly.newPlot(                        "6b58c264-859d-4a8d-803f-ad6df1035b83",                        [{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["black_stain_pencil_lead_heavy","","","torn_heavy_dried_stood_house"],"x":[0.0,0.7099364417012464,0.7099364417012464,0.0],"xaxis":"x","y":[-5.0,-5.0,-15.0,-15.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["heavy_dried_black_torn_stain","","","coat_torn_quite_tall_white"],"x":[0.7099364417012464,0.8737245411025376,0.8737245411025376,0.0],"xaxis":"x","y":[-10.0,-10.0,-25.0,-25.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["short_gave_far_sweet_street","","","quick_gave_failed_street_saw"],"x":[0.0,0.6727478785065517,0.6727478785065517,0.0],"xaxis":"x","y":[-35.0,-35.0,-45.0,-45.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["pot_failed_covered_contents_hard","","","tried_shone_quite_failed_worn"],"x":[0.0,0.7841628847640887,0.7841628847640887,0.0],"xaxis":"x","y":[-55.0,-55.0,-65.0,-65.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(133,20,75)"},"mode":"lines","text":["worn_stain_drop_dust_beat","","","barn_fall_china_bank_soft"],"x":[0.0,0.8695614532580362,0.8695614532580362,0.0],"xaxis":"x","y":[-75.0,-75.0,-85.0,-85.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["failed_pot_contents_covered_tried","","","worn_big_barn_fall_china"],"x":[0.7841628847640887,1.0450917043567305,1.0450917043567305,0.8695614532580362],"xaxis":"x","y":[-60.0,-60.0,-80.0,-80.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["gave_street_failed_short_quick","","","failed_worn_big_pot_fall"],"x":[0.6727478785065517,1.069508241832879,1.069508241832879,1.0450917043567305],"xaxis":"x","y":[-40.0,-40.0,-70.0,-70.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["coat_torn_dried_heavy_black","","","failed_street_gave_worn_pot"],"x":[0.8737245411025376,1.1379417642463796,1.1379417642463796,1.069508241832879],"xaxis":"x","y":[-17.5,-17.5,-55.0,-55.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,220,0)"},"mode":"lines","text":["desk_chair_sat_cover_corner","","","cover_steady_went_shone_dark"],"x":[0.0,0.7661908643802522,0.7661908643802522,0.0],"xaxis":"x","y":[-95.0,-95.0,-105.0,-105.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,220,0)"},"mode":"lines","text":["tree_room_gives_dark_green","","","screen_went_let_gives_burned"],"x":[0.0,0.7997766649898732,0.7997766649898732,0.0],"xaxis":"x","y":[-115.0,-115.0,-125.0,-125.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,220,0)"},"mode":"lines","text":["cover_desk_chair_blue_steady","","","gives_burned_screen_room_let"],"x":[0.7661908643802522,0.9484741495459519,0.9484741495459519,0.7997766649898732],"xaxis":"x","y":[-100.0,-100.0,-120.0,-120.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(40,35,35)"},"mode":"lines","text":["near_screen_green__","","","tree_near_fall_drifts_brought"],"x":[0.0,0.7490544810400137,0.7490544810400137,0.0],"xaxis":"x","y":[-135.0,-135.0,-145.0,-145.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["went_gives_cover_desk_dark","","","near_tree_screen_fall_drifts"],"x":[0.9484741495459519,1.0768473738572593,1.0768473738572593,0.7490544810400137],"xaxis":"x","y":[-110.0,-110.0,-140.0,-140.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["failed_black_coat_street_gave","","","gives_went_screen_near_cover"],"x":[1.1379417642463796,1.3249774560199035,1.3249774560199035,1.0768473738572593],"xaxis":"x","y":[-36.25,-36.25,-125.0,-125.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["sun_bowl_shone_pink_soft","","","pink_blue_used_tall_small"],"x":[0.0,0.6981995044720265,0.6981995044720265,0.0],"xaxis":"x","y":[-165.0,-165.0,-175.0,-175.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["drifts_seen_pink_stood_salt","","","pink_sun_blue_shone_bowl"],"x":[0.0,0.834440606524687,0.834440606524687,0.6981995044720265],"xaxis":"x","y":[-155.0,-155.0,-170.0,-170.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["horse_tall_day_night_brown","","","need_food_spring_needed_came"],"x":[0.0,0.7643436617562973,0.7643436617562973,0.0],"xaxis":"x","y":[-185.0,-185.0,-195.0,-195.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["food_drink_cup_salt_sweet","","","port_glass_food_cup_contents"],"x":[0.0,0.6963325045201142,0.6963325045201142,0.0],"xaxis":"x","y":[-205.0,-205.0,-215.0,-215.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["horse_need_food_tall_spring","","","food_cup_contents_port_glass"],"x":[0.7643436617562973,1.0316168309890619,1.0316168309890619,0.6963325045201142],"xaxis":"x","y":[-190.0,-190.0,-210.0,-210.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["pink_sun_blue_rose_came","","","food_horse_cup_tall_need"],"x":[0.834440606524687,1.207870301753695,1.207870301753695,1.0316168309890619],"xaxis":"x","y":[-162.5,-162.5,-200.0,-200.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["pot_tired_served_china_taste","","","taste_tree_served_sent_cut"],"x":[0.0,0.7592557999590236,0.7592557999590236,0.0],"xaxis":"x","y":[-235.0,-235.0,-245.0,-245.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["tired_port_drink_taste_serve","","","taste_served_pot_sent_tree"],"x":[0.0,0.8100227787031731,0.8100227787031731,0.7592557999590236],"xaxis":"x","y":[-225.0,-225.0,-240.0,-240.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["saw_hold_dry_kept_best","","","sent_rings_hold_gold_worn"],"x":[0.0,0.6729302983064405,0.6729302983064405,0.0],"xaxis":"x","y":[-255.0,-255.0,-265.0,-265.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["hold_sent_rings_saw_kept","","","rings_clean_bright_make_used"],"x":[0.6729302983064405,0.8676753026211969,0.8676753026211969,0.0],"xaxis":"x","y":[-260.0,-260.0,-275.0,-275.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["taste_tired_served_pot_fine","","","rings_hold_sent_used_clean"],"x":[0.8100227787031731,1.1393392685550854,1.1393392685550854,0.8676753026211969],"xaxis":"x","y":[-232.5,-232.5,-267.5,-267.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["pink_food_horse_cup_tall","","","taste_hold_served_tired_sent"],"x":[1.207870301753695,1.3159622965080087,1.3159622965080087,1.1393392685550854],"xaxis":"x","y":[-181.25,-181.25,-250.0,-250.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["failed_black_coat_chair_street","","","taste_pink_food_horse_hold"],"x":[1.3249774560199035,1.3771522705231485,1.3771522705231485,1.3159622965080087],"xaxis":"x","y":[-80.625,-80.625,-215.625,-215.625],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["right_dog_day_came_small","","","dog_tender_drink_grass_spring"],"x":[0.0,0.6486729207144407,0.6486729207144407,0.0],"xaxis":"x","y":[-295.0,-295.0,-305.0,-305.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["saw_hole_dog_takes_makes","","","dog_grass_tender_drink_spring"],"x":[0.0,0.8078941395278781,0.8078941395278781,0.6486729207144407],"xaxis":"x","y":[-285.0,-285.0,-300.0,-300.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(133,20,75)"},"mode":"lines","text":["add_drop_comes_great_fast","","","bank_poor_jump_free_great"],"x":[0.0,0.7205482123974118,0.7205482123974118,0.0],"xaxis":"x","y":[-335.0,-335.0,-345.0,-345.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(133,20,75)"},"mode":"lines","text":["great_lack_young_makes_old","","","add_great_bank_poor_jump"],"x":[0.0,0.818923906295568,0.818923906295568,0.7205482123974118],"xaxis":"x","y":[-325.0,-325.0,-340.0,-340.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(133,20,75)"},"mode":"lines","text":["went_size_jump_start_spring","","","add_great_bank_comes_drop"],"x":[0.0,0.9264348251797423,0.9264348251797423,0.818923906295568],"xaxis":"x","y":[-315.0,-315.0,-332.5,-332.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["dog_grass_drink_tender_small","","","add_great_jump_bank_fast"],"x":[0.8078941395278781,1.2509150596886933,1.2509150596886933,0.9264348251797423],"xaxis":"x","y":[-292.5,-292.5,-323.75,-323.75],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,220,0)"},"mode":"lines","text":["office_needed_bank_ran_boy","","","door_needed_bad_old_"],"x":[0.0,0.7941060355592697,0.7941060355592697,0.0],"xaxis":"x","y":[-355.0,-355.0,-365.0,-365.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(40,35,35)"},"mode":"lines","text":["tight_open_watch_glass_covered","","","slide_tight_cord_wooden_glass"],"x":[0.0,0.6984157432784135,0.6984157432784135,0.0],"xaxis":"x","y":[-375.0,-375.0,-385.0,-385.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["door_needed_office_bank_bad","","","tight_glass_open_slide_watch"],"x":[0.7941060355592697,1.017979800235745,1.017979800235745,0.6984157432784135],"xaxis":"x","y":[-360.0,-360.0,-380.0,-380.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["left_cord_cloth_gold_day","","","open_cloth_make_good_"],"x":[0.0,0.7842157479045966,0.7842157479045966,0.0],"xaxis":"x","y":[-395.0,-395.0,-405.0,-405.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["cloth_left_open_cord_gold","","","smell_cloth_clean_dirt_times"],"x":[0.7842157479045966,0.8552088482809009,0.8552088482809009,0.0],"xaxis":"x","y":[-400.0,-400.0,-415.0,-415.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["tight_door_needed_open_glass","","","cloth_smell_clean_left_times"],"x":[1.017979800235745,1.2063839954976665,1.2063839954976665,0.8552088482809009],"xaxis":"x","y":[-370.0,-370.0,-407.5,-407.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["neat_time_right_needs_","","","needs_just_strong_cause_crack"],"x":[0.0,0.7701962343277591,0.7701962343277591,0.0],"xaxis":"x","y":[-425.0,-425.0,-435.0,-435.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["note_lead_cause_bad_small","","","tried_drop_cause_bad_right"],"x":[0.0,0.6940420418285337,0.6940420418285337,0.0],"xaxis":"x","y":[-445.0,-445.0,-455.0,-455.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["cause_bad_tried_note_lead","","","words_times_leave_right_lost"],"x":[0.6940420418285337,0.9067800331201084,0.9067800331201084,0.0],"xaxis":"x","y":[-450.0,-450.0,-465.0,-465.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["needs_just_time_strong_heavy","","","cause_words_bad_right_lost"],"x":[0.7701962343277591,0.983996777003714,0.983996777003714,0.9067800331201084],"xaxis":"x","y":[-430.0,-430.0,-457.5,-457.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["cloth_open_tight_door_needed","","","cause_tried_needs_just_right"],"x":[1.2063839954976665,1.2958559136149554,1.2958559136149554,0.983996777003714],"xaxis":"x","y":[-388.75,-388.75,-443.75,-443.75],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["free_men_lack_new_don","","","men_stop_steady_work_act"],"x":[0.0,0.7935312247622268,0.7935312247622268,0.0],"xaxis":"x","y":[-485.0,-485.0,-495.0,-495.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["served_free_far_comes_bowl","","","men_stop_steady_free_work"],"x":[0.0,0.9375945299802989,0.9375945299802989,0.7935312247622268],"xaxis":"x","y":[-475.0,-475.0,-490.0,-490.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["road_dirt_wide_street_low","","","cold_let_start_lay_ice"],"x":[0.0,0.7853862936952023,0.7853862936952023,0.0],"xaxis":"x","y":[-505.0,-505.0,-515.0,-515.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["men_free_served_comes_bowl","","","road_lay_deep_cold_let"],"x":[0.9375945299802989,1.0923010504494461,1.0923010504494461,0.7853862936952023],"xaxis":"x","y":[-482.5,-482.5,-510.0,-510.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["store_start_serve_friends_corner","","","friends_note_leave_girl_new"],"x":[0.0,0.6599933461320105,0.6599933461320105,0.0],"xaxis":"x","y":[-525.0,-525.0,-535.0,-535.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["men_free_road_lay_work","","","friends_store_serve_girl_leave"],"x":[1.0923010504494461,1.1838705757176233,1.1838705757176233,0.6599933461320105],"xaxis":"x","y":[-496.25,-496.25,-530.0,-530.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["big_torn_stop_port_brought","","","barn_dirt_watch_size_quick"],"x":[0.0,0.7064214069213968,0.7064214069213968,0.0],"xaxis":"x","y":[-545.0,-545.0,-555.0,-555.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["blow_clear_big_lost_sharp","","","quick_pencil_carved_hung_cut"],"x":[0.7064214069213968,0.8546786604284868,0.8546786604284868,0.0],"xaxis":"x","y":[-550.0,-550.0,-565.0,-565.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["men_friends_free_road_store","","","blow_quick_cut_sharp_clear"],"x":[1.1838705757176233,1.1994076633472956,1.1994076633472956,0.8546786604284868],"xaxis":"x","y":[-513.125,-513.125,-557.5,-557.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(133,20,75)"},"mode":"lines","text":["box_square_seen_wooden_poor","","","fence_corner_long_square_slide"],"x":[0.0,0.7793686559432533,0.7793686559432533,0.0],"xaxis":"x","y":[-575.0,-575.0,-585.0,-585.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,220,0)"},"mode":"lines","text":["bring_long_home_took_road","","","long_carved_base_read_form"],"x":[0.0,0.7866391616532893,0.7866391616532893,0.0],"xaxis":"x","y":[-595.0,-595.0,-605.0,-605.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["square_fence_box_slide_corner","","","long_bring_carved_base_read"],"x":[0.7793686559432533,1.03630936779378,1.03630936779378,0.7866391616532893],"xaxis":"x","y":[-580.0,-580.0,-600.0,-600.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(40,35,35)"},"mode":"lines","text":["room_form_night_dull_","","","short_room_write_tell_struck"],"x":[0.0,0.6947031518227607,0.6947031518227607,0.0],"xaxis":"x","y":[-615.0,-615.0,-625.0,-625.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(40,35,35)"},"mode":"lines","text":["clock_little_rare_needs_work","","","mark_low_beat_struck_base"],"x":[0.0,0.8533402191116879,0.8533402191116879,0.0],"xaxis":"x","y":[-635.0,-635.0,-645.0,-645.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(40,35,35)"},"mode":"lines","text":["room_short_write_tell_struck","","","clock_mark_struck_beat_low"],"x":[0.6947031518227607,0.9687876693089803,0.9687876693089803,0.8533402191116879],"xaxis":"x","y":[-620.0,-620.0,-640.0,-640.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["long_square_fence_box_bring","","","struck_room_clock_mark_low"],"x":[1.03630936779378,1.2368572594790903,1.2368572594790903,0.9687876693089803],"xaxis":"x","y":[-590.0,-590.0,-630.0,-630.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["men_friends_wide_stop_quick","","","long_struck_box_room_base"],"x":[1.1994076633472956,1.290312061965805,1.290312061965805,1.2368572594790903],"xaxis":"x","y":[-535.3125,-535.3125,-610.0,-610.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["cloth_open_cause_door_tight","","","long_men_mark_struck_corner"],"x":[1.2958559136149554,1.3473116151225286,1.3473116151225286,1.290312061965805],"xaxis":"x","y":[-416.25,-416.25,-572.65625,-572.65625],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["add_dog_great_jump_bank","","","cloth_slide_long_watch_cause"],"x":[1.2509150596886933,1.3864749858928866,1.3864749858928866,1.3473116151225286],"xaxis":"x","y":[-308.125,-308.125,-494.453125,-494.453125],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["taste_shone_food_failed_tree","","","slide_cloth_dirt_note_cause"],"x":[1.3771522705231485,1.4843310933858551,1.4843310933858551,1.3864749858928866],"xaxis":"x","y":[-148.125,-148.125,-401.2890625,-401.2890625],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","hovertext":["heavy_dried_black_torn_stain","failed_pot_contents_covered_tried","gave_street_failed_short_quick","coat_torn_dried_heavy_black","cover_desk_chair_blue_steady","went_gives_cover_desk_dark","failed_black_coat_street_gave","horse_need_food_tall_spring","pink_sun_blue_rose_came","hold_sent_rings_saw_kept","taste_tired_served_pot_fine","pink_food_horse_cup_tall","failed_black_coat_chair_street","dog_grass_drink_tender_small","door_needed_office_bank_bad","cloth_left_open_cord_gold","tight_door_needed_open_glass","cause_bad_tried_note_lead","needs_just_time_strong_heavy","cloth_open_tight_door_needed","men_free_served_comes_bowl","men_free_road_lay_work","blow_clear_big_lost_sharp","men_friends_free_road_store","square_fence_box_slide_corner","room_short_write_tell_struck","long_square_fence_box_bring","men_friends_wide_stop_quick","cloth_open_cause_door_tight","add_dog_great_jump_bank","taste_shone_food_failed_tree"],"marker":{"color":"black"},"mode":"markers","showlegend":false,"x":[0.7099364417012464,0.7841628847640887,0.6727478785065517,0.8737245411025376,0.7661908643802522,0.9484741495459519,1.1379417642463796,0.7643436617562973,0.834440606524687,0.6729302983064405,0.8100227787031731,1.207870301753695,1.3249774560199035,0.8078941395278781,0.7941060355592697,0.7842157479045966,1.017979800235745,0.6940420418285337,0.7701962343277591,1.2063839954976665,0.9375945299802989,1.0923010504494461,0.7064214069213968,1.1838705757176233,0.7793686559432533,0.6947031518227607,1.03630936779378,1.1994076633472956,1.2958559136149554,1.2509150596886933,1.3771522705231485],"y":[-10.0,-60.0,-40.0,-17.5,-100.0,-110.0,-36.25,-190.0,-162.5,-260.0,-232.5,-181.25,-80.625,-292.5,-360.0,-400.0,-370.0,-450.0,-430.0,-388.75,-482.5,-496.25,-550.0,-513.125,-580.0,-620.0,-590.0,-535.3125,-416.25,-308.125,-148.125],"type":"scatter"},{"hoverinfo":"text","hovertext":["worn_big_barn_fall_china","failed_worn_big_pot_fall","failed_street_gave_worn_pot","gives_burned_screen_room_let","near_tree_screen_fall_drifts","gives_went_screen_near_cover","pink_sun_blue_shone_bowl","food_cup_contents_port_glass","food_horse_cup_tall_need","taste_served_pot_sent_tree","rings_hold_sent_used_clean","taste_hold_served_tired_sent","taste_pink_food_horse_hold","dog_grass_tender_drink_spring","add_great_bank_poor_jump","add_great_bank_comes_drop","add_great_jump_bank_fast","tight_glass_open_slide_watch","cloth_smell_clean_left_times","cause_words_bad_right_lost","cause_tried_needs_just_right","men_stop_steady_free_work","road_lay_deep_cold_let","friends_store_serve_girl_leave","blow_quick_cut_sharp_clear","long_bring_carved_base_read","clock_mark_struck_beat_low","struck_room_clock_mark_low","long_struck_box_room_base","long_men_mark_struck_corner","cloth_slide_long_watch_cause","slide_cloth_dirt_note_cause"],"marker":{"color":"black"},"mode":"markers","showlegend":false,"x":[0.8695614532580362,1.0450917043567305,1.069508241832879,0.7997766649898732,0.7490544810400137,1.0768473738572593,0.6981995044720265,0.6963325045201142,1.0316168309890619,0.7592557999590236,0.8676753026211969,1.1393392685550854,1.3159622965080087,0.6486729207144407,0.7205482123974118,0.818923906295568,0.9264348251797423,0.6984157432784135,0.8552088482809009,0.9067800331201084,0.983996777003714,0.7935312247622268,0.7853862936952023,0.6599933461320105,0.8546786604284868,0.7866391616532893,0.8533402191116879,0.9687876693089803,1.2368572594790903,1.290312061965805,1.3473116151225286,1.3864749858928866],"y":[-80.0,-70.0,-55.0,-120.0,-140.0,-125.0,-170.0,-210.0,-200.0,-240.0,-267.5,-250.0,-215.625,-300.0,-340.0,-332.5,-323.75,-380.0,-407.5,-457.5,-443.75,-490.0,-510.0,-530.0,-557.5,-600.0,-640.0,-630.0,-610.0,-572.65625,-494.453125,-401.2890625],"type":"scatter"}],                        {"autosize":false,"height":1175,"hovermode":"closest","showlegend":false,"width":1000,"xaxis":{"mirror":"allticks","rangemode":"tozero","showgrid":false,"showline":true,"showticklabels":true,"ticks":"outside","type":"linear","zeroline":false},"yaxis":{"mirror":"allticks","rangemode":"tozero","showgrid":false,"showline":true,"showticklabels":true,"tickmode":"array","ticks":"outside","ticktext":["24_black_stain_pencil","40_torn_heavy_dried","61_coat_torn_quite","57_short_gave_far","16_quick_gave_failed","46_pot_failed_covered","48_tried_shone_quite","59_worn_stain_drop","22_barn_fall_china","21_desk_chair_sat","9_cover_steady_went","19_tree_room_gives","10_screen_went_let","56_near_screen_green","20_tree_near_fall","12_drifts_seen_pink","17_sun_bowl_shone","38_pink_blue_used","36_horse_tall_day","8_need_food_spring","39_food_drink_cup","58_port_glass_food","15_tired_port_drink","43_pot_tired_served","4_taste_tree_served","47_saw_hold_dry","34_sent_rings_hold","41_rings_clean_bright","37_saw_hole_dog","25_right_dog_day","63_dog_tender_drink","13_went_size_jump","60_great_lack_young","29_add_drop_comes","23_bank_poor_jump","18_office_needed_bank","52_door_needed_bad","45_tight_open_watch","11_slide_tight_cord","26_left_cord_cloth","44_open_cloth_make","2_smell_cloth_clean","53_neat_time_right","1_needs_just_strong","55_note_lead_cause","33_tried_drop_cause","32_words_times_leave","49_served_free_far","64_free_men_lack","50_men_stop_steady","27_road_dirt_wide","5_cold_let_start","30_store_start_serve","6_friends_note_leave","14_big_torn_stop","0_barn_dirt_watch","35_quick_pencil_carved","7_box_square_seen","28_fence_corner_long","54_bring_long_home","42_long_carved_base","62_room_form_night","31_short_room_write","51_clock_little_rare","3_mark_low_beat"],"tickvals":[-5.0,-15.0,-25.0,-35.0,-45.0,-55.0,-65.0,-75.0,-85.0,-95.0,-105.0,-115.0,-125.0,-135.0,-145.0,-155.0,-165.0,-175.0,-185.0,-195.0,-205.0,-215.0,-225.0,-235.0,-245.0,-255.0,-265.0,-275.0,-285.0,-295.0,-305.0,-315.0,-325.0,-335.0,-345.0,-355.0,-365.0,-375.0,-385.0,-395.0,-405.0,-415.0,-425.0,-435.0,-445.0,-455.0,-465.0,-475.0,-485.0,-495.0,-505.0,-515.0,-525.0,-535.0,-545.0,-555.0,-565.0,-575.0,-585.0,-595.0,-605.0,-615.0,-625.0,-635.0,-645.0],"type":"linear","zeroline":false,"range":[-650.0,0.0]},"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":22,"color":"Black"},"text":"\u003cb\u003eHierarchical Clustering\u003c\u002fb\u003e","x":0.5,"xanchor":"center","yanchor":"top"},"hoverlabel":{"font":{"size":16,"family":"Rockwell"},"bgcolor":"white"},"plot_bgcolor":"#ECEFF1"},                        {"responsive": true}                    )                };                            </script>
</div>
<p>The hierarchical structure is based on how topics emerge based on the
similarity of their embeddings, however, we can often find topics that
we think should be merged based on our own knowledge. For example,
despite their embeddings having a relatively large distance between
them, topic 2 and 14 both appear to be about food.</p>
</div>
<div class="section level4">
<h4 id="looking-at-topic-contents">Looking at Topic Contents<a class="anchor" aria-label="anchor" href="#looking-at-topic-contents"></a>
</h4>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">topic_representations</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">Topic</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">14</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;   Topic Count                     Name</span></span>
<span><span class="co">#&gt; 1     2    17 2_smell_cloth_clean_dirt</span></span>
<span><span class="co">#&gt; 2    14    11    14_big_torn_stop_port</span></span>
<span><span class="co">#&gt;                                                        Representation</span></span>
<span><span class="co">#&gt; 1 smell, cloth, clean, dirt, times, tender, neat, burned, bring, dust</span></span>
<span><span class="co">#&gt; 2       big, torn, stop, port, brought, blow, sharp, lost, cut, clear</span></span>
<span><span class="co">#&gt;                                                      keybert</span></span>
<span><span class="co">#&gt; 1 burned_sharp_dirt_cloth_dust_floor_tender_water_makes_deep</span></span>
<span><span class="co">#&gt; 2    cut_water_sharp_clear_small_hard_blow_torn_brought_lost</span></span>
<span><span class="co">#&gt;                                                          mmr</span></span>
<span><span class="co">#&gt; 1 dirt_cloth_dust_clean_tender_burned_neat_bring_times_smell</span></span>
<span><span class="co">#&gt; 2       sharp_cut_port_torn_clear_blow_lost_stop_brought_big</span></span>
<span><span class="co">#&gt;                             flanT5</span></span>
<span><span class="co">#&gt; 1 bringing a smoky smell to a room</span></span>
<span><span class="co">#&gt; 2       a splinter cut to the port</span></span></code></pre></div>
<p>For larger topics we might need to use more sophisticated language
analysis tools, but since these topics are relatively small, we can just
examine exemplars.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">topic</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">14</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">sentence</span>, <span class="va">topic</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 28 × 2</span></span></span>
<span><span class="co">#&gt;    sentence                                           topic</span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>                                              <span style="color: #949494; font-style: italic;">&lt;int&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> wipe the grease off his dirty face.                    2</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> the ship was torn apart on the sharp reef.            14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> the navy attacked the big task force.                 14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> the fin was sharp and cut the clear water.            14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> bail the boat to stop it from sinking.                14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> a cramp is no small danger on a swim.                 14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> mud was spattered on the front of his white shirt.     2</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> the pirates seized the crew of the lost ship.         14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> a rag will soak up spilled water.                      2</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> they felt gay when the ship arrived in port.          14</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># ℹ 18 more rows</span></span></span></code></pre></div>
<p>I am pretty happy that these two topics could be merged into a larger
“food” topic, to do this we use the bt_merge_topics function:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bt_merge_topics.html">bt_merge_topics</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                topics_to_merge <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">14</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Topics merged &amp; input model updated accordingly</span></span></code></pre></div>
<p>We have been maintaining a dataframe all along that is tracking each
step we’ve completed, it would be good to now update that dataframe with
our new topics.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>merged_topics <span class="op">=</span> <span class="va">topic_model</span><span class="op">$</span><span class="va">topics_</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="reducing-outliers">Reducing Outliers<a class="anchor" aria-label="anchor" href="#reducing-outliers"></a>
</h3>
<p>One feature of hdbscan is the outlier category, which can be quite
large. Sometimes we might want to redistribute these outlier documents
so that they fall within one of the existing topics. There are a number
of methods to achieve this and it is good practice to look at different
parameters and different methods when reducing outliers as it can be
quite difficult to redistribute outlier documents while maintaining
clarity within your topics. To this end, you should consider project
goal is before implementing any of these methods, it is more important
to have concise and coherent topics or to force most/all of your
documents into topics, is it a balance of the two?</p>
<p>The methods currently available to us are:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Tokenset Similarity:</strong> Divides each documents into
tokensets and calculates the c-TF-IDF cosine similarity between each
tokenset and each topic. The summation of each cosine similarity score
for each topic across each outlier document gives the most similar topic
for each outlier document.</p></li>
<li><p><strong>Embeddings:</strong> Measures the cosine similarity
between embeddings for each outlier document and each topic. If we have
passed an empty embedding model to bt_compile_model (which we did), we
must specify an embedding model to be used with this function.</p></li>
<li><p><strong>c-TF-IDF:</strong> Calculates the c-TF-IDF cosine
similarity for each outlier document and topic and redistributes
outliers based on the topic with which it has the highest
similarity.</p></li>
</ol>
<p>We can play with all outlier strategies as, unlike when we merge
topics or fit the model, the bt_outlier_* functions do not update the
model, they only output a df with each document, their current topic
classification and the potential new topics. We must update the model
using bt_update_topics to actually change the topics within the
model.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">outliers_ts_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_outliers_tokenset_similarity.html">bt_outliers_tokenset_similarity</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                                   documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                                   topics <span class="op">=</span> <span class="va">topic_model</span><span class="op">$</span><span class="va">topics_</span>,</span>
<span>                                                   threshold <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">outliers_embed</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_outliers_embeddings.html">bt_outliers_embeddings</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                         documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                         topics <span class="op">=</span> <span class="va">topic_model</span><span class="op">$</span><span class="va">topics_</span>,</span>
<span>                                         embeddings <span class="op">=</span> <span class="va">reduced_embeddings</span>,</span>
<span>                                         embedding_model <span class="op">=</span> <span class="va">embedder</span>,</span>
<span>                                         threshold <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">outliers_ctfidf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_outliers_ctfidf.html">bt_outliers_ctfidf</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                      documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                      topics <span class="op">=</span> <span class="va">topic_model</span><span class="op">$</span><span class="va">topics_</span>,</span>
<span>                                      threshold <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span></code></pre></div>
<p>It would be useful now to look at how each method has redistributed
the outlier topics. The graph below shows how outliers have been
redistributed to topics below topic 12. You can see how each strategy
does not redistribute topics in the same way, the embedding strategy for
example, has found that 6 outlier documents are best represented by
topic 1, while no other strategy has found any outlier documents that
are best represented by topic 1. The embedding method has also
redistributed all outlier documents, while the c-TF-IDF and tokenset
similarity methods have left certain documents as outliers. This is
where playing around with the threshold parameter, to find a good fit
for your data and chosen strategy, is important.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>outliers_ts_sim <span class="op">=</span> <span class="va">outliers_ts_sim</span><span class="op">$</span><span class="va">new_topics</span>,</span>
<span>         outliers_embed <span class="op">=</span> <span class="va">outliers_embed</span><span class="op">$</span><span class="va">new_topics</span>,</span>
<span>         outliers_ctfidf <span class="op">=</span> <span class="va">outliers_ctfidf</span><span class="op">$</span><span class="va">new_topics</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">merged_topics</span> <span class="op">==</span> <span class="op">-</span><span class="fl">1</span>,</span>
<span>         <span class="va">outliers_ctfidf</span> <span class="op">&lt;</span> <span class="fl">12</span>,</span>
<span>         <span class="va">outliers_embed</span> <span class="op">&lt;</span> <span class="fl">12</span>,</span>
<span>         <span class="va">outliers_ts_sim</span> <span class="op">&lt;</span> <span class="fl">12</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">outliers_ts_sim</span>, <span class="va">outliers_embed</span>, <span class="va">outliers_ctfidf</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_longer.html" class="external-link">pivot_longer</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/everything.html" class="external-link">everything</a></span><span class="op">(</span><span class="op">)</span>, names_to <span class="op">=</span> <span class="st">"outlier_distribution_strategy"</span>, values_to <span class="op">=</span> <span class="st">"topic"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">topic</span><span class="op">)</span>, fill <span class="op">=</span> <span class="va">outlier_distribution_strategy</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html" class="external-link">geom_bar</a></span><span class="op">(</span>position <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/position_dodge.html" class="external-link">position_dodge2</a></span><span class="op">(</span>preserve <span class="op">=</span> <span class="st">"single"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Numbers"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Count"</span>,</span>
<span>       title <span class="op">=</span> <span class="st">"Number of outliers in each topic after redistribution"</span>,</span>
<span>       fill <span class="op">=</span> <span class="st">"Outlier redistribution strategy"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_colour_discrete.html" class="external-link">scale_fill_discrete</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>outliers_ctfidf <span class="op">=</span> <span class="st">"c-TF-IDF"</span>,</span>
<span>                               outliers_embed <span class="op">=</span> <span class="st">"Embeddings"</span>,</span>
<span>                               outliers_ts_sim <span class="op">=</span> <span class="st">"Tokenset similarity"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="manipulating-the-model_files/figure-html/unnamed-chunk-10-1.png" width="700"></p>
<p>You should take a look at some of the documents which have been
redistributed and the topic which they have been redistributed to before
deciding on the best strategy for your data. Unfortunately, this can be
quite laborious for large amounts of data with many topics.</p>
<p>Once you have settled on a new list of topics that you are happy
with, we can update the dataframe we have been keeping. For example, if
after looking at the data we decided that the Tokenset Similarity method
was the most appropriate:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>new_topics <span class="op">=</span> <span class="va">outliers_ts_sim</span><span class="op">$</span><span class="va">new_topics</span><span class="op">)</span></span>
<span></span>
<span><span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">merged_topics</span> <span class="op">==</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">merged_topics</span>, <span class="va">new_topics</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 189 × 2</span></span></span>
<span><span class="co">#&gt;    merged_topics new_topics</span></span>
<span><span class="co">#&gt;            <span style="color: #949494; font-style: italic;">&lt;int&gt;</span>      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span>            -<span style="color: #BB0000;">1</span>         -<span style="color: #BB0000;">1</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span>            -<span style="color: #BB0000;">1</span>         46</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span>            -<span style="color: #BB0000;">1</span>         -<span style="color: #BB0000;">1</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span>            -<span style="color: #BB0000;">1</span>         59</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span>            -<span style="color: #BB0000;">1</span>         -<span style="color: #BB0000;">1</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span>            -<span style="color: #BB0000;">1</span>         41</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span>            -<span style="color: #BB0000;">1</span>         -<span style="color: #BB0000;">1</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span>            -<span style="color: #BB0000;">1</span>         34</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span>            -<span style="color: #BB0000;">1</span>         56</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span>            -<span style="color: #BB0000;">1</span>         -<span style="color: #BB0000;">1</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># ℹ 179 more rows</span></span></span></code></pre></div>
<p>While you can update your model with the new topics, first consider
the future use of your model, if your intention is to use your model to
fit new data, is it better to fit based on the original, more selective
topic classification or the less selective classification that outlier
reduction has resulted in?</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bt_update_topics.html">bt_update_topics</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                 documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                 new_topics <span class="op">=</span> <span class="va">outliers_ts_sim</span><span class="op">$</span><span class="va">new_topics</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Input model updated</span></span></code></pre></div>
<p>If you would like to have a deeper look at what else we can do using
bertopic, refer to the BertopicR function documentation and the BERTopic
python library, <a href="https://maartengr.github.io/BERTopic/index.html" class="external-link uri">https://maartengr.github.io/BERTopic/index.html</a>.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Jack Penzer, Aoife Ryan.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
